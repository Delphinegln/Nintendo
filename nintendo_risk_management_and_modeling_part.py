# -*- coding: utf-8 -*-
"""PARTIE 5

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OqyCve-vbc8mKulh7J0fCQztYB80t6v9

# **Value-at-Risk**
"""

import numpy as np
import scipy.stats as stats
import pandas as pd
import datetime as dt
import yfinance as yf
import matplotlib.pyplot as plt

# Download a company stock data and calculate log returns:
Nintendo = yf.download("NTDOY", start = "2015-09-30", end = "2025-09-30")['Close']
data = Nintendo
data['returns'] = np.log(data / data.shift(1))
data.tail()

"""**1. VaR formula based on parametric approach**"""

# Portfolio information
last_stock_price = Nintendo.iloc[-1].values[0]  # -1 refers to the last element in the Pandas Series
number_of_shares = 1000
portfolio_value = last_stock_price * number_of_shares   # Current market value of the portfolio
expected_return = data['returns'].mean()   # Expected return of the portfolio
volatility = data['returns'].std()        # Standard deviation (volatility) of portfolio returns
alpha = 0.05 # Confidence level

# Calculate the z-score based on the desired confidence level
z_score = stats.norm.ppf(1 - alpha)

# Calculate VaR based on the parametric formula
var = expected_return - z_score * volatility
var_portfolio = portfolio_value * (expected_return - z_score * volatility) #changer la devise

print(f" VaR at {alpha * 100}% confidence level: {var*100:.2f}% or $ {var_portfolio:.0f}")

#Plot the results
import numpy as np
import matplotlib.pyplot as plt

num_samples = 1000
portfolio_returns = np.random.normal(expected_return, volatility, num_samples)

plt.figure(figsize=(8,6))
plt.hist(portfolio_returns, bins=50, density=True, alpha=0.7, color='b', label='Portfolio Returns')

# Ensure correct VaR placement
plt.axvline(x=var, color='r', linestyle='dashed', linewidth=2, label=f'VaR at {alpha * 100}%')

# Set limits to make sure negative values are visible
plt.xlim(min(portfolio_returns) - 0.05, max(portfolio_returns) + 0.05)

# Labels and legend
plt.title('Parametric VaR')
plt.xlabel('Portfolio Returns')
plt.ylabel('Frequency')
plt.legend()
plt.grid(True)
plt.show()

print(f"Min Simulated Return: {min(portfolio_returns)*100:.2f}%")
print(f"VaR at {alpha * 100}%: {var*100:.2f}%")

# Calculate VaR in 1 month (22 trading days) based on the parametric formula

n_days = 22
exp_return_1m = (expected_return+1)**22 - 1
var = exp_return_1m - z_score * volatility * np.sqrt(n_days)
var_portfolio = portfolio_value * var

print(f" VaR at {alpha * 100}% confidence level in 1 month: {var*100:.2f}% or $ {var_portfolio:.0f}")

"""**2. VaR formula based on historical approach**"""

# Calculate the historical VaR using the quantile function:

returns = data['returns']
alpha = 0.05
var = returns.quantile(alpha)
var_portfolio = var * portfolio_value
print(f"Historical VaR at {alpha * 100}% confidence level: {var*100:.2f}% or $ {var_portfolio:.0f}")

"""There is a 5% probability of experiencing a loss of approximately 3.22% of the portfolio value."""

# Create a histogram of returns
plt.hist(returns, bins=30, density=True, alpha=0.7, color='b', label='Portfolio Returns')
plt.axvline(x=var, color='red', linestyle='dashed', linewidth=2, label=f'VaR at {alpha * 100}%')
plt.xlabel('Returns')
plt.ylabel('Density')
plt.title('Historical VaR')
plt.legend()
plt.grid(True)
plt.show()

print(f"Min Simulated Return: {min(portfolio_returns)*100:.2f}%")
print(f"VaR at {alpha * 100}%: {var*100:.2f}%")

"""# **Backtesting and Stress testing**"""

# Portfolio information
Nintendo = yf.download("NTDOY", start = "2015-09-30", end = "2025-09-30")['Close']
data = Nintendo
data['returns'] = np.log(data / data.shift(1))

last_stock_price = Nintendo.iloc[-1].values[0] # -1 refers to the last element in the Pandas Series
number_of_shares = 1000
portfolio_value = last_stock_price * number_of_shares # Current market value of the portfolio
returns = data['returns'] # Daily stock returns
expected_return = data['returns'].mean()  # Expected return of the portfolio
volatility = data['returns'].std()        # Standard deviation (volatility) of portfolio returns
alpha = 0.01 # Confidence level

# Calculate the z-score based on the desired confidence level
z_score = stats.norm.ppf(1 - alpha)

# Calculate VaR based on the parametric formula
var_portfolio = portfolio_value * (expected_return - z_score * volatility)

# Set cutoff based on VaR/position
cutOff = var_portfolio / portfolio_value

# Filter returns below the cutoff
returns2 = returns[returns <= cutOff]
n2 = len(returns2)
n = len(returns)

# Calculate the ratio of days where return is below the cutoff
ratio = n2 * 1. / (n * 1.)

print(f"n2 = {n2}")
print(f"Cutoff = {cutOff*100:.2f}%")
print(f"Ratio = {ratio*100:.2f}%")

"""# **Expected Shortfall**"""

# Calculate ES based on the parametric formula
alpha = 0.05
# Calculate the z-score based on the desired confidence level
z_score = stats.norm.ppf(1 - alpha)

# Calculate Parametric VaR
var_par = expected_return - z_score * volatility
var_par_portfolio = portfolio_value * (expected_return - z_score * volatility)

# Distribution's probability density function (PDF) is used
# to approximate the integral and calculate the weighted average of the tail.
es_par = expected_return - (stats.norm.pdf(z_score)/(1-alpha)) * volatility
es_par_portfolio = portfolio_value * es_par

print(f"Parametric VaR at {alpha * 100}% confidence level: {var_par*100:.2f}% or $ {var_par_portfolio:.0f}")
print(f"Parametric ES at {alpha * 100}% confidence level: {es_par*100:.2f}% or $ {es_par_portfolio:.2f}")

# Calculate ES based on the historical formula

var_h = returns.quantile(alpha)
var_h_portfolio = var_h * portfolio_value

returns_tail = returns[returns <= var_h]
es_h = np.mean(returns_tail)
es_h_portfolio = portfolio_value*es_h

print(f"Historical VaR at {alpha * 100}% confidence level: {var_h*100:.2f}% or $ {var_h_portfolio:.0f}")
print(f"Historical ES at {alpha * 100}% confidence level: {es_h*100:.2f}% or $ {es_h_portfolio:.0f}")

"""# **Credit Risk Modelling**"""

# Stock data:
S0 = Nintendo.iloc[-1].values[0] # stock initial price
r = data['returns'].mean() # stock expected return
sigma = data['returns'].std() # stock standard deviation
T = 1 # one year period

I = 100000 # number of simulations

# Simulate future stock prices using geometric Brownian motion:
ST = S0 * np.exp((r - 0.5 * sigma ** 2) * T + sigma * np.sqrt(T) * np.random.standard_normal(I))

# Assumed parameters for default simulation:
L = 0.5 # Loss level 50%
p = 0.01 # 1% of the probability of default

# Simulate default events with Poisson distribution, i.e,
# Generate I samples with the given default probability (p) scaled by the time (T).
D = np.random.poisson(p * T, I)
# Limit the number of defaults to one.
D = np.where(D > 1, 1, D)

import math

# Calculate discounted average simulated value of the asset at time T:
# discount factor * mean of the simulated future stock prices
math.exp(-r * T) * np.mean(ST)
# 99.94767178982691

# Discounted average simulated price of the asset at time T, adjusted for the losses from default.
S0_CVA = math.exp(-r * T) * np.mean((1 - L * D) * ST)
# (1 - L * D) represents the remaining value after accounting for the loss rate.
S0_CVA
# 99.45931576393053

# Credit VaR as the discounted average of the future losses in the case of a default,
# taking into account the loss rate and simulated default events.
CreditVaR = math.exp(-r * T) * np.mean(L * D * ST)
CreditVaR
# 0.4883560258963962

# Current price of the asset adjusted by the simulated Credit VaR.
S0_adj = S0 - CreditVaR
S0_adj
# 99.5116439741036

# Number of default events and therewith loss events.
np.count_nonzero(L * D * ST)
# 978 - we observe approx. 1,000 losses due to credit risk,
# as we assumed default probability of 1% and 100,000 simulations.

# Plot the losses due to risk-neutrally expected default (stock)
# In the large majority of cases there is no loss to observe:
plt.figure(figsize=(10, 6))
plt.hist(L * D * ST, bins=50)
plt.xlabel('Loss')
plt.ylabel('Frequency')
plt.ylim(ymax=450)

